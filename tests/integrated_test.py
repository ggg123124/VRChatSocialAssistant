"""
VRChat ç¤¾äº¤è¾…åŠ©å·¥å…· - åŠŸèƒ½é›†æˆæµ‹è¯•ç¨‹åº

æä¾›å‘½ä»¤è¡Œäº¤äº’å¼ç•Œé¢ï¼Œé›†æˆæµ‹è¯•æ‰€æœ‰å·²å¼€å‘çš„æ¨¡å—ï¼š
- éŸ³é¢‘é‡‡é›†
- VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹
- è¯´è¯äººè¯†åˆ«
- è¯­éŸ³è½¬æ–‡æœ¬ (STT)
- è®°å¿†ç®¡ç†

ä½¿ç”¨æ–¹æ³•:
    python tests/integrated_test.py [é€‰é¡¹]

é€‰é¡¹:
    --help, -h          æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    --init              ä»…è¿è¡Œåˆå§‹åŒ–æ£€æŸ¥
    --module <åç§°>     ç›´æ¥è¿›å…¥æŒ‡å®šæ¨¡å—æµ‹è¯•
    --full              ç›´æ¥è¿è¡Œå®Œæ•´æµç¨‹æµ‹è¯•
    --debug             å¯ç”¨è°ƒè¯•æ¨¡å¼
"""

import sys
import os
import logging
import argparse
import time
import numpy as np
from pathlib import Path
from typing import Optional, Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'src'))

# å¯¼å…¥æµ‹è¯•å·¥å…·
from tests.test_utils import (
    print_title, print_subtitle, print_separator,
    print_success, print_error, print_warning, print_info,
    show_menu, get_user_input, get_number_input, confirm,
    wait_for_enter, clear_screen, print_table,
    generate_test_audio, generate_speech_audio, generate_silence,
    PerformanceTimer, StatisticsCollector, format_timestamp,
    format_duration, safe_execute
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('tests/integrated_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class IntegratedTest:
    """é›†æˆæµ‹è¯•ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        self.modules_initialized = {
            'audio': False,
            'vad': False,
            'speaker': False,
            'stt': False,
            'memory': False
        }
        
        # æ¨¡å—å®ä¾‹
        self.audio_capturer = None
        self.vad_detector = None
        self.speaker_recognizer = None
        self.stt_recognizer = None
        self.memory_manager = None
        
        # ç»Ÿè®¡æ”¶é›†å™¨
        self.stats = StatisticsCollector()
        
        # é…ç½®è·¯å¾„
        self.config_dir = project_root / 'config'
        self.data_dir = project_root / 'data'
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        self.data_dir.mkdir(exist_ok=True)
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print_title("VRChat ç¤¾äº¤è¾…åŠ©å·¥å…· - åŠŸèƒ½é›†æˆæµ‹è¯•")
        print()
        print_info("æ¬¢è¿ä½¿ç”¨é›†æˆæµ‹è¯•å·¥å…·ï¼")
        print_info("æœ¬å·¥å…·å°†å¸®åŠ©æ‚¨æµ‹è¯•æ‰€æœ‰å·²å¼€å‘çš„æ¨¡å—åŠŸèƒ½ã€‚")
        print()
        
        # æ˜¾ç¤ºä¸»èœå•
        self.show_main_menu()
    
    def show_main_menu(self):
        """æ˜¾ç¤ºä¸»èœå•"""
        while True:
            options = {
                '1': 'ç³»ç»Ÿåˆå§‹åŒ– - æ£€æŸ¥ç¯å¢ƒå¹¶åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—',
                '2': 'å•æ¨¡å—æµ‹è¯• - æµ‹è¯•å„ä¸ªæ¨¡å—çš„ç‹¬ç«‹åŠŸèƒ½',
                '3': 'å®Œæ•´æµç¨‹æµ‹è¯• - è¿è¡Œç«¯åˆ°ç«¯çš„è¯­éŸ³å¤„ç†æµç¨‹',
                '4': 'æ•°æ®ç®¡ç† - ç®¡ç†å¥½å‹æ¡£æ¡ˆå’Œå¯¹è¯è®°å½•',
                '5': 'ç³»ç»Ÿä¿¡æ¯ - æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯'
            }
            
            choice = show_menu("ä¸»èœå•", options)
            
            if choice == '0':
                if confirm("ç¡®å®šè¦é€€å‡ºå—ï¼Ÿ"):
                    self.cleanup()
                    print_success("å·²é€€å‡ºï¼Œå†è§ï¼")
                    break
            elif choice == '1':
                self.initialize_system()
            elif choice == '2':
                self.show_module_test_menu()
            elif choice == '3':
                self.run_full_pipeline_test()
            elif choice == '4':
                self.show_data_management_menu()
            elif choice == '5':
                self.show_system_info()
            
            if choice != '0':
                wait_for_enter()
    
    def initialize_system(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print_title("ç³»ç»Ÿåˆå§‹åŒ–")
        print()
        
        print_info("å¼€å§‹åˆå§‹åŒ–æ£€æŸ¥...")
        print()
        
        # 1. æ£€æŸ¥é…ç½®æ–‡ä»¶
        print_subtitle("1. æ£€æŸ¥é…ç½®æ–‡ä»¶", "-")
        self.check_config_files()
        print()
        
        # 2. æ£€æŸ¥æ•°æ®ç›®å½•
        print_subtitle("2. æ£€æŸ¥æ•°æ®ç›®å½•", "-")
        self.check_data_directories()
        print()
        
        # 3. åˆå§‹åŒ–å„æ¨¡å—
        print_subtitle("3. åˆå§‹åŒ–æ¨¡å—", "-")
        self.initialize_modules()
        print()
        
        # æ˜¾ç¤ºåˆå§‹åŒ–ç»“æœ
        self.show_initialization_result()
    
    def check_config_files(self):
        """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
        config_files = [
            'audio_config.yaml',
            'memory_config.yaml',
            'speaker_recognition_config.yaml',
            'stt_config.yaml'
        ]
        
        for config_file in config_files:
            config_path = self.config_dir / config_file
            if config_path.exists():
                print_success(f"{config_file} - å­˜åœ¨")
            else:
                print_warning(f"{config_file} - ä¸å­˜åœ¨ï¼ˆå°†ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰")
    
    def check_data_directories(self):
        """æ£€æŸ¥æ•°æ®ç›®å½•"""
        directories = [
            'data',
            'data/profiles',
            'data/conversations',
            'data/vector_db',
            'data/speaker_profiles'
        ]
        
        for dir_path in directories:
            full_path = project_root / dir_path
            if full_path.exists():
                print_success(f"{dir_path}/ - å­˜åœ¨")
            else:
                full_path.mkdir(parents=True, exist_ok=True)
                print_info(f"{dir_path}/ - å·²åˆ›å»º")
    
    def initialize_modules(self):
        """åˆå§‹åŒ–å„æ¨¡å—"""
        # éŸ³é¢‘é‡‡é›†æ¨¡å—
        print("åˆå§‹åŒ–éŸ³é¢‘é‡‡é›†æ¨¡å—...")
        result = self.init_audio_module()
        if result:
            print_success("éŸ³é¢‘é‡‡é›†æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        else:
            print_error("éŸ³é¢‘é‡‡é›†æ¨¡å—åˆå§‹åŒ–å¤±è´¥")
        
        # VAD æ¨¡å—
        print("\nåˆå§‹åŒ– VAD æ¨¡å—...")
        result = self.init_vad_module()
        if result:
            print_success("VAD æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        else:
            print_error("VAD æ¨¡å—åˆå§‹åŒ–å¤±è´¥")
        
        # è¯´è¯äººè¯†åˆ«æ¨¡å—
        print("\nåˆå§‹åŒ–è¯´è¯äººè¯†åˆ«æ¨¡å—...")
        result = self.init_speaker_module()
        if result:
            print_success("è¯´è¯äººè¯†åˆ«æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        else:
            print_error("è¯´è¯äººè¯†åˆ«æ¨¡å—åˆå§‹åŒ–å¤±è´¥")
        
        # STT æ¨¡å—
        print("\nåˆå§‹åŒ– STT æ¨¡å—...")
        result = self.init_stt_module()
        if result:
            print_success("STT æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        else:
            print_error("STT æ¨¡å—åˆå§‹åŒ–å¤±è´¥")
        
        # è®°å¿†ç®¡ç†æ¨¡å—
        print("\nåˆå§‹åŒ–è®°å¿†ç®¡ç†æ¨¡å—...")
        result = self.init_memory_module()
        if result:
            print_success("è®°å¿†ç®¡ç†æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        else:
            print_error("è®°å¿†ç®¡ç†æ¨¡å—åˆå§‹åŒ–å¤±è´¥")
    
    def init_audio_module(self) -> bool:
        """åˆå§‹åŒ–éŸ³é¢‘é‡‡é›†æ¨¡å—"""
        try:
            from audio_capture import DeviceManager
            device_manager = DeviceManager()
            devices = device_manager.list_devices()
            if devices:
                self.modules_initialized['audio'] = True
                return True
        except Exception as e:
            logger.error(f"éŸ³é¢‘æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
        return False
    
    def init_vad_module(self) -> bool:
        """åˆå§‹åŒ– VAD æ¨¡å—"""
        try:
            from vad import VADDetector
            self.vad_detector = VADDetector(
                sample_rate=16000,
                threshold=0.5,
                min_speech_duration_ms=250,
                max_speech_duration_ms=10000,
                min_silence_duration_ms=300
            )
            self.modules_initialized['vad'] = True
            return True
        except Exception as e:
            logger.error(f"VAD æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
        return False
    
    def init_speaker_module(self) -> bool:
        """åˆå§‹åŒ–è¯´è¯äººè¯†åˆ«æ¨¡å—"""
        try:
            from speaker_recognition import SpeakerRecognizer
            self.speaker_recognizer = SpeakerRecognizer()
            self.modules_initialized['speaker'] = True
            return True
        except Exception as e:
            logger.error(f"è¯´è¯äººè¯†åˆ«æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
        return False
    
    def init_stt_module(self) -> bool:
        """åˆå§‹åŒ– STT æ¨¡å—"""
        try:
            from stt import STTRecognizer
            self.stt_recognizer = STTRecognizer()
            self.modules_initialized['stt'] = True
            return True
        except Exception as e:
            logger.error(f"STT æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
        return False
    
    def init_memory_module(self) -> bool:
        """åˆå§‹åŒ–è®°å¿†ç®¡ç†æ¨¡å—"""
        try:
            from memory import MemoryManager
            config_path = self.config_dir / 'memory_config.yaml'
            if config_path.exists():
                self.memory_manager = MemoryManager(str(config_path))
            else:
                self.memory_manager = MemoryManager()
            self.modules_initialized['memory'] = True
            return True
        except Exception as e:
            logger.error(f"è®°å¿†ç®¡ç†æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
        return False
    
    def show_initialization_result(self):
        """æ˜¾ç¤ºåˆå§‹åŒ–ç»“æœ"""
        print_subtitle("åˆå§‹åŒ–ç»“æœ", "=")
        
        total = len(self.modules_initialized)
        success = sum(self.modules_initialized.values())
        
        for module, status in self.modules_initialized.items():
            status_text = "âœ“ æˆåŠŸ" if status else "âœ— å¤±è´¥"
            if status:
                print_success(f"{module.upper()} æ¨¡å—: {status_text}")
            else:
                print_error(f"{module.upper()} æ¨¡å—: {status_text}")
        
        print()
        print(f"æ€»è®¡: {success}/{total} æ¨¡å—åˆå§‹åŒ–æˆåŠŸ ({success/total*100:.0f}%)")
        
        if success == total:
            print_success("\nâœ“ æ‰€æœ‰æ¨¡å—åˆå§‹åŒ–æˆåŠŸï¼")
        elif success > 0:
            print_warning(f"\nâš  éƒ¨åˆ†æ¨¡å—åˆå§‹åŒ–å¤±è´¥ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        else:
            print_error(f"\nâœ— æ‰€æœ‰æ¨¡å—åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
    
    def show_module_test_menu(self):
        """æ˜¾ç¤ºæ¨¡å—æµ‹è¯•èœå•"""
        while True:
            options = {
                '1': 'éŸ³é¢‘é‡‡é›†æµ‹è¯•',
                '2': 'VAD æ£€æµ‹æµ‹è¯•',
                '3': 'è¯´è¯äººè¯†åˆ«æµ‹è¯•',
                '4': 'STT è¯­éŸ³è½¬æ–‡æœ¬æµ‹è¯•',
                '5': 'è®°å¿†ç®¡ç†æµ‹è¯•'
            }
            
            choice = show_menu("å•æ¨¡å—æµ‹è¯•", options)
            
            if choice == '0':
                break
            elif choice == '1':
                self.test_audio_capture()
            elif choice == '2':
                self.test_vad()
            elif choice == '3':
                self.test_speaker_recognition()
            elif choice == '4':
                self.test_stt()
            elif choice == '5':
                self.test_memory()
            
            if choice != '0':
                wait_for_enter()
    
    def test_audio_capture(self):
        """æµ‹è¯•éŸ³é¢‘é‡‡é›†æ¨¡å—"""
        print_title("éŸ³é¢‘é‡‡é›†æ¨¡å—æµ‹è¯•")
        
        if not self.modules_initialized['audio']:
            print_error("éŸ³é¢‘æ¨¡å—æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œç³»ç»Ÿåˆå§‹åŒ–")
            return
        
        options = {
            '1': 'è®¾å¤‡æšä¸¾æµ‹è¯• - åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è®¾å¤‡',
            '2': 'çŸ­æ—¶é‡‡é›†æµ‹è¯• - é‡‡é›†5ç§’éŸ³é¢‘',
        }
        
        choice = show_menu("éŸ³é¢‘é‡‡é›†æµ‹è¯•", options)
        
        if choice == '1':
            self.test_audio_devices()
        elif choice == '2':
            self.test_audio_capture_short()
    
    def test_audio_devices(self):
        """æµ‹è¯•è®¾å¤‡æšä¸¾"""
        print_subtitle("éŸ³é¢‘è®¾å¤‡åˆ—è¡¨")
        
        try:
            from audio_capture import DeviceManager
            device_manager = DeviceManager()
            
            devices = device_manager.list_devices()
            
            if not devices:
                print_warning("æœªæ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡")
                return
            
            print(f"\næ‰¾åˆ° {len(devices)} ä¸ªéŸ³é¢‘è®¾å¤‡:\n")
            
            headers = ["ç´¢å¼•", "åç§°", "é€šé“æ•°", "é‡‡æ ·ç‡", "é©±åŠ¨"]
            rows = []
            
            for device in devices:
                rows.append([
                    str(device['index']),
                    device['name'][:40],
                    str(device.get('maxInputChannels', 0)),
                    str(device.get('defaultSampleRate', 0)),
                    device.get('hostApi', 'Unknown')
                ])
            
            print_table(headers, rows)
            
            # æ˜¾ç¤ºé»˜è®¤è®¾å¤‡
            print("\né»˜è®¤è®¾å¤‡:")
            loopback = device_manager.get_default_wasapi_loopback()
            if loopback:
                print_success(f"WASAPI Loopback: {loopback['name']}")
            else:
                print_warning("æœªæ‰¾åˆ° WASAPI Loopback è®¾å¤‡")
        
        except Exception as e:
            logger.error(f"è®¾å¤‡æšä¸¾å¤±è´¥: {e}", exc_info=True)
            print_error(f"è®¾å¤‡æšä¸¾å¤±è´¥: {e}")
    
    def test_audio_capture_short(self):
        """çŸ­æ—¶é‡‡é›†æµ‹è¯•"""
        print_subtitle("çŸ­æ—¶é‡‡é›†æµ‹è¯•ï¼ˆ5ç§’ï¼‰")
        
        try:
            from audio_capture import AudioCapturer, DeviceManager
            
            device_manager = DeviceManager()
            loopback = device_manager.get_default_wasapi_loopback()
            
            if not loopback:
                print_error("æœªæ‰¾åˆ° WASAPI Loopback è®¾å¤‡")
                return
            
            print_info("ä½¿ç”¨è®¾å¤‡: " + loopback['name'])
            print_info("å¼€å§‹é‡‡é›† 5 ç§’éŸ³é¢‘...")
            print()
            
            capturer = AudioCapturer(
                loopback_device=loopback['index'],
                samplerate=16000,
                channels=1,
                chunk_size=480
            )
            
            frames = []
            
            def callback(audio_data, timestamp):
                frames.append(audio_data)
                if len(frames) % 10 == 0:
                    print(f"å·²é‡‡é›†: {len(frames)} å¸§", end='\r')
            
            capturer.set_loopback_callback(callback)
            capturer.start()
            
            time.sleep(5)
            
            capturer.stop()
            
            print()
            print_success(f"é‡‡é›†å®Œæˆï¼å…±é‡‡é›† {len(frames)} å¸§éŸ³é¢‘")
            
            if frames:
                audio_data = np.concatenate(frames)
                rms = np.sqrt(np.mean(audio_data ** 2))
                print(f"éŸ³é¢‘ RMS: {rms:.6f}")
                print(f"éŸ³é¢‘æ—¶é•¿: {len(audio_data) / 16000:.2f} ç§’")
        
        except Exception as e:
            logger.error(f"éŸ³é¢‘é‡‡é›†å¤±è´¥: {e}", exc_info=True)
            print_error(f"éŸ³é¢‘é‡‡é›†å¤±è´¥: {e}")
    
    def test_vad(self):
        """æµ‹è¯• VAD æ¨¡å—"""
        print_title("VAD è¯­éŸ³æ´»åŠ¨æ£€æµ‹æµ‹è¯•")
        
        if not self.modules_initialized['vad']:
            print_error("VAD æ¨¡å—æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œç³»ç»Ÿåˆå§‹åŒ–")
            return
        
        print_info("ä½¿ç”¨åˆæˆéŸ³é¢‘è¿›è¡Œ VAD æµ‹è¯•")
        print()
        
        try:
            # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘åºåˆ—ï¼šé™éŸ³-è¯­éŸ³-é™éŸ³-è¯­éŸ³-é™éŸ³
            print_subtitle("ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")
            
            sample_rate = 16000
            frame_size = 480  # 30ms
            frames = []
            
            # 1. é™éŸ³ 500ms
            print("ç”Ÿæˆé™éŸ³ç‰‡æ®µ (500ms)...")
            silence1 = generate_silence(0.5, sample_rate)
            for i in range(0, len(silence1), frame_size):
                frames.append(silence1[i:i+frame_size])
            
            # 2. è¯­éŸ³ 1 ç§’
            print("ç”Ÿæˆè¯­éŸ³ç‰‡æ®µ (1000ms)...")
            speech1 = generate_speech_audio(1.0, sample_rate)
            for i in range(0, len(speech1), frame_size):
                frames.append(speech1[i:i+frame_size])
            
            # 3. é™éŸ³ 500ms
            print("ç”Ÿæˆé™éŸ³ç‰‡æ®µ (500ms)...")
            silence2 = generate_silence(0.5, sample_rate)
            for i in range(0, len(silence2), frame_size):
                frames.append(silence2[i:i+frame_size])
            
            # 4. è¯­éŸ³ 800ms
            print("ç”Ÿæˆè¯­éŸ³ç‰‡æ®µ (800ms)...")
            speech2 = generate_speech_audio(0.8, sample_rate)
            for i in range(0, len(speech2), frame_size):
                frames.append(speech2[i:i+frame_size])
            
            # 5. é™éŸ³ 500ms
            print("ç”Ÿæˆé™éŸ³ç‰‡æ®µ (500ms)...")
            silence3 = generate_silence(0.5, sample_rate)
            for i in range(0, len(silence3), frame_size):
                frames.append(silence3[i:i+frame_size])
            
            print_success(f"æµ‹è¯•éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼Œå…± {len(frames)} å¸§")
            print()
            
            # å¤„ç†éŸ³é¢‘
            print_subtitle("VAD æ£€æµ‹")
            print("é¢„æœŸç»“æœ: æ£€æµ‹åˆ° 2 ä¸ªè¯­éŸ³ç‰‡æ®µ")
            print()
            
            detected_segments = []
            
            def speech_callback(segment, metadata):
                detected_segments.append(metadata)
                print(f"\nâœ“ æ£€æµ‹åˆ°è¯­éŸ³ç‰‡æ®µ #{len(detected_segments)}:")
                print(f"  æ—¶é•¿: {metadata['duration']:.2f} ç§’")
                print(f"  ç½®ä¿¡åº¦: {metadata['avg_confidence']:.3f}")
                print(f"  æ ·æœ¬æ•°: {metadata['num_samples']}")
            
            self.vad_detector.set_callback(speech_callback)
            
            timestamp = time.time()
            for i, frame in enumerate(frames):
                if len(frame) == frame_size:
                    self.vad_detector.process_audio(frame, timestamp)
                    timestamp += 0.03
                
                if (i + 1) % 10 == 0:
                    print(f"å¤„ç†è¿›åº¦: {i+1}/{len(frames)} å¸§", end='\r')
            
            print()
            print()
            
            # æ˜¾ç¤ºç»Ÿè®¡
            stats = self.vad_detector.get_statistics()
            print_subtitle("VAD ç»Ÿè®¡ä¿¡æ¯")
            print(f"å¤„ç†å¸§æ•°: {stats['total_frames_processed']}")
            print(f"æ£€æµ‹ç‰‡æ®µæ•°: {stats['speech_segments_detected']}")
            print(f"æ€»è¯­éŸ³æ—¶é•¿: {stats['total_speech_duration']:.2f} ç§’")
            print(f"å¹³å‡å¤„ç†æ—¶é—´: {stats['avg_processing_time_ms']:.2f} ms")
            print(f"ä¸¢å¸§æ•°: {stats['frames_dropped']}")
            
            if stats['speech_segments_detected'] >= 1:
                print()
                print_success(f"æµ‹è¯•æˆåŠŸï¼æ£€æµ‹åˆ° {len(detected_segments)} ä¸ªè¯­éŸ³ç‰‡æ®µ")
            else:
                print()
                print_warning("æœªæ£€æµ‹åˆ°è¯­éŸ³ç‰‡æ®µ")
        
        except Exception as e:
            logger.error(f"VAD æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
            print_error(f"VAD æµ‹è¯•å¤±è´¥: {e}")
    
    def test_speaker_recognition(self):
        """æµ‹è¯•è¯´è¯äººè¯†åˆ«æ¨¡å—"""
        print_title("è¯´è¯äººè¯†åˆ«æµ‹è¯•")
        
        if not self.modules_initialized['speaker']:
            print_error("è¯´è¯äººè¯†åˆ«æ¨¡å—æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œç³»ç»Ÿåˆå§‹åŒ–")
            return
        
        options = {
            '1': 'æ³¨å†Œæ–°å¥½å‹',
            '2': 'è¯†åˆ«æµ‹è¯•',
            '3': 'æŸ¥çœ‹å·²æ³¨å†Œå¥½å‹'
        }
        
        choice = show_menu("è¯´è¯äººè¯†åˆ«æµ‹è¯•", options)
        
        if choice == '1':
            self.test_speaker_register()
        elif choice == '2':
            self.test_speaker_recognize()
        elif choice == '3':
            self.test_speaker_list()
    
    def test_speaker_register(self):
        """æµ‹è¯•å£°çº¹æ³¨å†Œ"""
        print_subtitle("æ³¨å†Œæ–°å¥½å‹")
        
        friend_name = get_user_input("è¯·è¾“å…¥å¥½å‹å§“å")
        if not friend_name:
            print_warning("å·²å–æ¶ˆ")
            return
        
        # ç”Ÿæˆå¥½å‹IDï¼ˆä½¿ç”¨æ‹¼éŸ³æˆ–ç®€åŒ–åç§°ï¼‰
        # å¯¹äºä¸­æ–‡åå­—ï¼Œä½¿ç”¨å“ˆå¸Œå€¼
        if friend_name == "ä¹Ÿè®¸ä¸€åˆ‡éƒ½æ˜¯ä¸èƒ½" or friend_name == "ä¸èƒ½":
            friend_id = "friend_buneng"
        elif friend_name == "å°¾ç¿¼ç¨³å®šè„±å£³ç©¿ç”²é±¼" or friend_name == "é˜¿é±¼":
            friend_id = "friend_ayu"
        else:
            friend_id = f"friend_{int(time.time())}"
        
        print()
        print_info("é€‰æ‹©æ³¨å†Œæ–¹å¼ï¼š")
        print("  1. ä½¿ç”¨åˆæˆéŸ³é¢‘ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰")
        print("  2. å½•åˆ¶çœŸå®è¯­éŸ³ï¼ˆæ¨èï¼Œç”¨äºå®é™…ä½¿ç”¨ï¼‰")
        print()
        
        choice = get_user_input("è¯·é€‰æ‹© (1/2)", "2")
        
        if choice == "1":
            self._register_with_synthetic_audio(friend_id, friend_name)
        elif choice == "2":
            self._register_with_real_recording(friend_id, friend_name)
        else:
            print_warning("æ— æ•ˆé€‰æ‹©ï¼Œå·²å–æ¶ˆ")
    
    def _register_with_synthetic_audio(self, friend_id: str, friend_name: str):
        """ä½¿ç”¨åˆæˆéŸ³é¢‘æ³¨å†Œå£°çº¹"""
        print_info(f"æ­£åœ¨ä¸º {friend_name} ç”Ÿæˆå£°çº¹æ ·æœ¬ï¼ˆä½¿ç”¨åˆæˆéŸ³é¢‘ï¼‰...")
        
        # ç”Ÿæˆ3æ®µéŸ³é¢‘æ ·æœ¬
        audio_segments = []
        seed = hash(friend_name) % 1000
        
        for i in range(3):
            audio = generate_test_audio(duration=2.5, seed=seed + i)
            audio_segments.append(audio)
            print(f"  æ ·æœ¬ {i+1}: {len(audio)/16000:.2f}ç§’")
        
        # æ³¨å†Œ
        try:
            success = self.speaker_recognizer.register_speaker(
                friend_id=friend_id,
                name=friend_name,
                audio_segments=audio_segments,
                sample_rate=16000
            )
            
            if success:
                print_success(f"\n{friend_name} æ³¨å†ŒæˆåŠŸï¼")
                print(f"å¥½å‹ID: {friend_id}")
                print_warning("æ³¨æ„ï¼šåˆæˆéŸ³é¢‘ä»…ç”¨äºæµ‹è¯•ï¼Œå®é™…ä½¿ç”¨è¯·å½•åˆ¶çœŸå®è¯­éŸ³")
            else:
                print_error(f"\n{friend_name} æ³¨å†Œå¤±è´¥")
        
        except Exception as e:
            logger.error(f"å£°çº¹æ³¨å†Œå¤±è´¥: {e}", exc_info=True)
            print_error(f"æ³¨å†Œå¤±è´¥: {e}")
    
    def _register_with_real_recording(self, friend_id: str, friend_name: str):
        """ä½¿ç”¨çœŸå®å½•åˆ¶æ³¨å†Œå£°çº¹"""
        from audio_capture import DeviceManager, AudioCapturer
        
        print_title(f"ä¸º {friend_name} å½•åˆ¶å£°çº¹æ ·æœ¬")
        print_info("éœ€è¦å½•åˆ¶3æ®µè¯­éŸ³ï¼Œæ¯æ®µ2-3ç§’")
        print()
        
        # è·å–éŸ³é¢‘è®¾å¤‡ç®¡ç†å™¨
        device_manager = DeviceManager()
        
        # è·å– WASAPI Loopback è®¾å¤‡ï¼ˆç”¨äºå½•åˆ¶ç³»ç»Ÿ/æ¸¸æˆå£°éŸ³ï¼‰
        loopback_device = device_manager.get_default_wasapi_loopback()
        
        if not loopback_device:
            print_error("æœªæ‰¾åˆ° WASAPI Loopback è®¾å¤‡")
            print_warning("æ­¤è®¾å¤‡ç”¨äºå½•åˆ¶æ¸¸æˆä¸­æ’­æ”¾çš„å£°éŸ³")
            return
        
        # æ˜¾ç¤ºä½¿ç”¨çš„è®¾å¤‡
        print_subtitle("éŸ³é¢‘é‡‡é›†è®¾å¤‡")
        print()
        print_info(f"ä½¿ç”¨è®¾å¤‡: {loopback_device['name']}")
        print_info("è®¾å¤‡ç±»å‹: WASAPI Loopback (ç³»ç»ŸéŸ³é¢‘å›ç¯)")
        print()
        print_warning("æ³¨æ„: æ­¤æ¨¡å¼å½•åˆ¶çš„æ˜¯æ¸¸æˆä¸­æ’­æ”¾çš„å£°éŸ³")
        print("      è¯·åœ¨æ¸¸æˆä¸­è®©å¥½å‹è¯´è¯ï¼Œè€Œä¸æ˜¯å¯¹ç€éº¦å…‹é£è¯´è¯")
        print()
        
        print_warning("å½•åˆ¶æ³¨æ„äº‹é¡¹ï¼š")
        print("  1. ç¡®ä¿æ¸¸æˆéŸ³é‡åˆé€‚ï¼ˆä¸è¦å¤ªå°ï¼‰")
        print("  2. å½•åˆ¶æ—¶è¯·è®©æ¸¸æˆä¸­çš„å¥½å‹è¯´è¯")
        print("  3. å°½é‡å‡å°‘å…¶ä»–å£°éŸ³å¹²æ‰°ï¼ˆèƒŒæ™¯éŸ³ä¹ã€å…¶ä»–ç©å®¶ç­‰ï¼‰")
        print("  4. æ¯æ®µå½•éŸ³è®©å¥½å‹è¯´ä¸åŒçš„å†…å®¹")
        print("  5. å»ºè®®å¥½å‹å•ç‹¬è¯´è¯ï¼Œé¿å…å¤šäººåŒæ—¶å‘è¨€")
        print()
        
        if not confirm("å‡†å¤‡å¥½å¼€å§‹å½•åˆ¶äº†å—ï¼Ÿ"):
            print_warning("å·²å–æ¶ˆ")
            return
        
        audio_segments = []
        
        # å½•åˆ¶3æ®µéŸ³é¢‘
        for i in range(3):
            print()
            print_subtitle(f"å½•åˆ¶ç¬¬ {i+1} æ®µè¯­éŸ³")
            
            if i == 0:
                print_info("å»ºè®®å†…å®¹ï¼šè®©å¥½å‹ä»‹ç»è‡ªå·±ï¼Œä¾‹å¦‚ï¼šâ€œå¤§å®¶å¥½ï¼Œæˆ‘æ˜¯XXXâ€")
            elif i == 1:
                print_info("å»ºè®®å†…å®¹ï¼šè®©å¥½å‹éšæ„èŠå¤©ï¼Œä¾‹å¦‚ï¼šè°ˆè®ºæ¸¸æˆã€å¤©æ°”ç­‰")
            else:
                print_info("å»ºè®®å†…å®¹ï¼šè®©å¥½å‹å†è¯´ä¸€æ®µè¯ï¼Œä»»æ„å†…å®¹")
            
            print()
            input("æŒ‰å›è½¦é”®å¼€å§‹å½•åˆ¶...")
            
            # å½•åˆ¶éŸ³é¢‘
            try:
                print_info("â— æ­£åœ¨å½•åˆ¶... ï¼ˆå½•åˆ¶3ç§’ï¼Œè¯·è®©æ¸¸æˆä¸­çš„å¥½å‹å¼€å§‹è¯´è¯ï¼‰")
                
                recorded_audio = []
                
                def loopback_callback(audio_data, timestamp):
                    recorded_audio.append(audio_data)
                
                # åˆ›å»ºé‡‡é›†å™¨ï¼ˆä½¿ç”¨ WASAPI Loopback å½•åˆ¶æ¸¸æˆå£°éŸ³ï¼‰
                capturer = AudioCapturer(
                    loopback_device=loopback_device['index'],
                    samplerate=16000,
                    channels=1,
                    chunk_size=480
                )
                capturer.set_loopback_callback(loopback_callback)
                
                capturer.start()
                time.sleep(3)  # å½•åˆ¶3ç§’
                capturer.stop()
                
                if recorded_audio:
                    audio_segment = np.concatenate(recorded_audio)
                    audio_segments.append(audio_segment)
                    
                    # è®¡ç®—éŸ³é‡
                    rms = np.sqrt(np.mean(audio_segment ** 2))
                    duration = len(audio_segment) / 16000
                    
                    print_success(f"âœ“ å½•åˆ¶å®Œæˆï¼æ—¶é•¿: {duration:.2f}ç§’ï¼ŒéŸ³é‡: {rms:.4f}")
                    
                    if rms < 0.001:
                        print_warning("è­¦å‘Šï¼šéŸ³é‡è¾ƒå°ï¼Œè¯·ç¡®è®¤æ¸¸æˆéŸ³é‡æ˜¯å¦æ­£å¸¸ï¼Œæˆ–å¥½å‹æ˜¯å¦åœ¨è¯´è¯")
                else:
                    print_error("å½•åˆ¶å¤±è´¥ï¼šæœªé‡‡é›†åˆ°éŸ³é¢‘")
                    return
            
            except Exception as e:
                logger.error(f"å½•åˆ¶éŸ³é¢‘å¤±è´¥: {e}", exc_info=True)
                print_error(f"å½•åˆ¶å¤±è´¥: {e}")
                return
        
        print()
        print_subtitle("æ­£åœ¨æ³¨å†Œå£°çº¹...")
        
        # æ³¨å†Œå£°çº¹
        try:
            success = self.speaker_recognizer.register_speaker(
                friend_id=friend_id,
                name=friend_name,
                audio_segments=audio_segments,
                sample_rate=16000
            )
            
            if success:
                print()
                print_success(f"âœ“ {friend_name} å£°çº¹æ³¨å†ŒæˆåŠŸï¼")
                print(f"å¥½å‹ID: {friend_id}")
                print(f"æ ·æœ¬æ•°: {len(audio_segments)}")
                print(f"æ€»æ—¶é•¿: {sum(len(seg)/16000 for seg in audio_segments):.2f}ç§’")
                print()
                print_info("å»ºè®®ç«‹å³è¿›è¡Œè¯†åˆ«æµ‹è¯•éªŒè¯å£°çº¹è´¨é‡")
            else:
                print_error(f"\n{friend_name} å£°çº¹æ³¨å†Œå¤±è´¥")
        
        except Exception as e:
            logger.error(f"å£°çº¹æ³¨å†Œå¤±è´¥: {e}", exc_info=True)
            print_error(f"æ³¨å†Œå¤±è´¥: {e}")
    
    def test_speaker_recognize(self):
        """æµ‹è¯•å£°çº¹è¯†åˆ«"""
        print_subtitle("å£°çº¹è¯†åˆ«æµ‹è¯•")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·²æ³¨å†Œçš„å¥½å‹
        registered = self.speaker_recognizer.get_registered_speakers()
        
        if not registered:
            print_warning("å°šæœªæ³¨å†Œä»»ä½•å¥½å‹ï¼Œè¯·å…ˆæ³¨å†Œå¥½å‹")
            return
        
        print(f"å½“å‰å·²æ³¨å†Œ {len(registered)} ä½å¥½å‹\n")
        
        # æ˜¾ç¤ºå¥½å‹åˆ—è¡¨
        for i, speaker_id in enumerate(registered, 1):
            info = self.speaker_recognizer.get_speaker_info(speaker_id)
            if info:
                print(f"  {i}. {info.name} (ID: {speaker_id})")
        
        print()
        print_info("é€‰æ‹©è¯†åˆ«æ¨¡å¼ï¼š")
        print("  1. ä½¿ç”¨åˆæˆéŸ³é¢‘æµ‹è¯•ï¼ˆå¿«é€ŸéªŒè¯ï¼‰")
        print("  2. å®æ—¶è¯†åˆ«æ¸¸æˆè¯­éŸ³ï¼ˆæ¸¸æˆå†…æµ‹è¯•ï¼‰")
        print()
        
        choice = get_user_input("è¯·é€‰æ‹© (1/2)", "2")
        
        if choice == "1":
            self._test_speaker_recognize_synthetic()
        elif choice == "2":
            self._test_speaker_recognize_realtime()
        else:
            print_warning("æ— æ•ˆé€‰æ‹©ï¼Œå·²å–æ¶ˆ")
    
    def _test_speaker_recognize_synthetic(self):
        """ä½¿ç”¨åˆæˆéŸ³é¢‘æµ‹è¯•è¯†åˆ«"""
        print_subtitle("åˆæˆéŸ³é¢‘è¯†åˆ«æµ‹è¯•")
        
        registered = self.speaker_recognizer.get_registered_speakers()
        first_speaker = registered[0]
        info = self.speaker_recognizer.get_speaker_info(first_speaker)
        
        print(f"ç”Ÿæˆ {info.name if info else first_speaker} çš„æµ‹è¯•éŸ³é¢‘...")
        
        seed = hash(info.name if info else first_speaker) % 1000
        test_audio = generate_test_audio(duration=2.0, seed=seed + 5)
        
        try:
            result = self.speaker_recognizer.recognize(
                audio_segment=test_audio,
                timestamp=time.time(),
                sample_rate=16000
            )
            
            print("\nè¯†åˆ«ç»“æœ:")
            print(f"  æ˜¯å¦åŒ¹é…: {'æ˜¯' if result.matched else 'å¦'}")
            
            if result.matched:
                matched_info = self.speaker_recognizer.get_speaker_info(result.speaker_id)
                print(f"  è¯†åˆ«ä¸º: {matched_info.name if matched_info else result.speaker_id}")
                print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f}")
            
            print(f"  å¤„ç†æ—¶é—´: {result.processing_time:.2f} ms")
            
            if result.similarity_scores:
                print("\n  ç›¸ä¼¼åº¦åˆ†æ•°:")
                for speaker_id, score in result.similarity_scores.items():
                    speaker_info = self.speaker_recognizer.get_speaker_info(speaker_id)
                    name = speaker_info.name if speaker_info else speaker_id
                    print(f"    {name}: {score:.3f}")
        
        except Exception as e:
            logger.error(f"å£°çº¹è¯†åˆ«å¤±è´¥: {e}", exc_info=True)
            print_error(f"è¯†åˆ«å¤±è´¥: {e}")
    
    def _test_speaker_recognize_realtime(self):
        """å®æ—¶è¯†åˆ«æ¸¸æˆè¯­éŸ³ä¸­çš„è¯´è¯äºº"""
        from audio_capture import DeviceManager, AudioCapturer
        import threading
        import queue
        
        print_title("å®æ—¶è¯´è¯äººè¯†åˆ«")
        print_info("ä»æ¸¸æˆéŸ³é¢‘ä¸­å®æ—¶è¯†åˆ«æ­£åœ¨è¯´è¯çš„äºº")
        print()
        
        # è·å– WASAPI Loopback è®¾å¤‡
        device_manager = DeviceManager()
        loopback_device = device_manager.get_default_wasapi_loopback()
        
        if not loopback_device:
            print_error("æœªæ‰¾åˆ° WASAPI Loopback è®¾å¤‡")
            return
        
        print_info(f"ä½¿ç”¨è®¾å¤‡: {loopback_device['name']}")
        print()
        
        # é…ç½®å‚æ•°
        print_subtitle("æµ‹è¯•é…ç½®")
        duration = get_number_input("æµ‹è¯•æ—¶é•¿ï¼ˆç§’ï¼Œ0è¡¨ç¤ºæ‰‹åŠ¨åœæ­¢ï¼‰", 30)
        
        print()
        print_warning("æç¤ºï¼š")
        print("  1. è¯·ç¡®ä¿æ¸¸æˆéŸ³é‡åˆé€‚")
        print("  2. è®©å·²æ³¨å†Œçš„å¥½å‹åœ¨æ¸¸æˆä¸­è¯´è¯")
        print("  3. ç¨‹åºå°†å®æ—¶æ˜¾ç¤ºè¯†åˆ«ç»“æœ")
        print("  4. æŒ‰ Ctrl+C å¯éšæ—¶åœæ­¢")
        print()
        
        if not confirm("å‡†å¤‡å¼€å§‹å®æ—¶è¯†åˆ«ï¼Ÿ"):
            return
        
        # åˆå§‹åŒ– VADï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
        if not self.vad_detector:
            from vad import VADDetector
            self.vad_detector = VADDetector(
                sample_rate=16000,
                threshold=0.5,
                min_speech_duration_ms=250,
                max_speech_duration_ms=10000,
                min_silence_duration_ms=300
            )
        
        # ç»Ÿè®¡æ•°æ®
        stats = {
            'total_segments': 0,
            'matched_segments': 0,
            'unknown_segments': 0,
            'speaker_counts': {},
            'start_time': time.time()
        }
        
        # æ§åˆ¶æ ‡å¿—
        running = {'flag': True}
        
        # è¯­éŸ³ç‰‡æ®µé˜Ÿåˆ—
        vad_queue = queue.Queue(maxsize=20)
        
        # VAD å›è°ƒ
        def vad_callback(segment, metadata):
            if running['flag']:
                vad_queue.put((segment, metadata, time.time()))
        
        self.vad_detector.set_callback(vad_callback)
        
        # éŸ³é¢‘é‡‡é›†å›è°ƒ
        def audio_callback(audio_data, timestamp):
            if running['flag']:
                try:
                    self.vad_detector.process_audio(audio_data, timestamp)
                except Exception as e:
                    logger.error(f"VADå¤„ç†é”™è¯¯: {e}")
        
        # è¯†åˆ«å¤„ç†çº¿ç¨‹
        def recognition_thread():
            while running['flag']:
                try:
                    segment, metadata, detect_time = vad_queue.get(timeout=1.0)
                    stats['total_segments'] += 1
                    
                    # è¯´è¯äººè¯†åˆ«
                    try:
                        result = self.speaker_recognizer.recognize(
                            audio_segment=segment,
                            timestamp=detect_time,
                            sample_rate=16000
                        )
                        
                        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                        elapsed = time.time() - stats['start_time']
                        
                        if result.matched:
                            stats['matched_segments'] += 1
                            info = self.speaker_recognizer.get_speaker_info(result.speaker_id)
                            speaker_name = info.name if info else result.speaker_id
                            
                            # ç»Ÿè®¡è¯´è¯æ¬¡æ•°
                            if speaker_name not in stats['speaker_counts']:
                                stats['speaker_counts'][speaker_name] = 0
                            stats['speaker_counts'][speaker_name] += 1
                            
                            # å®æ—¶æ˜¾ç¤º
                            print(f"\n[{format_duration(elapsed)}] ğŸ¤ {speaker_name}")
                            print(f"  ç½®ä¿¡åº¦: {result.confidence:.3f} | æ—¶é•¿: {metadata.get('duration', 0):.2f}s")
                            
                            # æ˜¾ç¤ºæ‰€æœ‰å€™é€‰äººçš„ç›¸ä¼¼åº¦
                            if result.similarity_scores and len(result.similarity_scores) > 1:
                                print("  å…¶ä»–å€™é€‰:")
                                sorted_scores = sorted(
                                    result.similarity_scores.items(),
                                    key=lambda x: x[1],
                                    reverse=True
                                )
                                for speaker_id, score in sorted_scores:
                                    if speaker_id != result.speaker_id:
                                        other_info = self.speaker_recognizer.get_speaker_info(speaker_id)
                                        other_name = other_info.name if other_info else speaker_id
                                        print(f"    {other_name}: {score:.3f}")
                        else:
                            stats['unknown_segments'] += 1
                            print(f"\n[{format_duration(elapsed)}] â“ æœªçŸ¥è¯´è¯äºº")
                            print(f"  æ—¶é•¿: {metadata.get('duration', 0):.2f}s")
                            
                            # æ˜¾ç¤ºç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆå³ä½¿æœªåŒ¹é…ï¼‰
                            if result.similarity_scores:
                                print("  ç›¸ä¼¼åº¦åˆ†æ•°:")
                                sorted_scores = sorted(
                                    result.similarity_scores.items(),
                                    key=lambda x: x[1],
                                    reverse=True
                                )
                                for speaker_id, score in sorted_scores[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                                    other_info = self.speaker_recognizer.get_speaker_info(speaker_id)
                                    other_name = other_info.name if other_info else speaker_id
                                    print(f"    {other_name}: {score:.3f}")
                    
                    except Exception as e:
                        logger.error(f"è¯†åˆ«é”™è¯¯: {e}", exc_info=True)
                        print_error(f"è¯†åˆ«é”™è¯¯: {e}")
                
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†çº¿ç¨‹é”™è¯¯: {e}", exc_info=True)
        
        # åˆ›å»ºé‡‡é›†å™¨
        try:
            capturer = AudioCapturer(
                loopback_device=loopback_device['index'],
                samplerate=16000,
                channels=1,
                chunk_size=480
            )
            capturer.set_loopback_callback(audio_callback)
        except Exception as e:
            print_error(f"éŸ³é¢‘é‡‡é›†å™¨åˆ›å»ºå¤±è´¥: {e}")
            return
        
        # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
        recog_thread = threading.Thread(target=recognition_thread, daemon=True)
        recog_thread.start()
        
        # å¼€å§‹é‡‡é›†
        print_separator()
        print_subtitle("å¼€å§‹å®æ—¶è¯†åˆ«")
        print_info("æŒ‰ Ctrl+C åœæ­¢è¯†åˆ«")
        print_separator()
        print()
        
        try:
            capturer.start()
            start_time = time.time()
            
            # ä¸»å¾ªç¯
            while running['flag']:
                time.sleep(0.5)
                
                # æ£€æŸ¥æ—¶é•¿
                if duration > 0 and (time.time() - start_time) >= duration:
                    print_info("\næµ‹è¯•æ—¶é•¿å·²åˆ°ï¼Œåœæ­¢è¯†åˆ«")
                    break
                
                # æ˜¾ç¤ºç®€å•çŠ¶æ€ï¼ˆæ¯5ç§’ï¼‰
                if int(time.time() - start_time) % 5 == 0:
                    elapsed = time.time() - start_time
                    print(f"\rè¿è¡Œä¸­... {format_duration(elapsed)} | "
                          f"æ£€æµ‹ç‰‡æ®µ: {stats['total_segments']} | "
                          f"è¯†åˆ«æˆåŠŸ: {stats['matched_segments']}",
                          end='', flush=True)
        
        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­è¯†åˆ«")
        finally:
            # åœæ­¢é‡‡é›†å’Œå¤„ç†
            running['flag'] = False
            capturer.stop()
            recog_thread.join(timeout=3)
        
        # æ˜¾ç¤ºç»Ÿè®¡æŠ¥å‘Š
        print("\n")
        print_separator("=")
        print_title("è¯†åˆ«ç»Ÿè®¡æŠ¥å‘Š")
        print_separator("=")
        
        total_time = time.time() - stats['start_time']
        
        print(f"\næµ‹è¯•æ—¶é•¿: {format_duration(total_time)}")
        print(f"æ£€æµ‹è¯­éŸ³ç‰‡æ®µ: {stats['total_segments']}")
        print(f"è¯†åˆ«æˆåŠŸ: {stats['matched_segments']}")
        print(f"æœªçŸ¥è¯´è¯äºº: {stats['unknown_segments']}")
        
        if stats['total_segments'] > 0:
            success_rate = stats['matched_segments'] / stats['total_segments'] * 100
            print(f"è¯†åˆ«ç‡: {success_rate:.1f}%")
        
        if stats['speaker_counts']:
            print("\nè¯´è¯ç»Ÿè®¡:")
            sorted_speakers = sorted(
                stats['speaker_counts'].items(),
                key=lambda x: x[1],
                reverse=True
            )
            for speaker_name, count in sorted_speakers:
                print(f"  {speaker_name}: {count} æ¬¡")
        
        print()
        print_success("âœ“ å®æ—¶è¯†åˆ«æµ‹è¯•å®Œæˆï¼")
    
    def test_speaker_list(self):
        """æŸ¥çœ‹å·²æ³¨å†Œå¥½å‹"""
        print_subtitle("å·²æ³¨å†Œå¥½å‹åˆ—è¡¨")
        
        registered = self.speaker_recognizer.get_registered_speakers()
        
        if not registered:
            print_warning("å°šæœªæ³¨å†Œä»»ä½•å¥½å‹")
            return
        
        print(f"\nå…± {len(registered)} ä½å¥½å‹:\n")
        
        for i, speaker_id in enumerate(registered, 1):
            info = self.speaker_recognizer.get_speaker_info(speaker_id)
            if info:
                print(f"{i}. {info.name}")
                print(f"   ID: {speaker_id}")
                print(f"   æ ·æœ¬æ•°: {info.sample_count}")
                print(f"   å¹³å‡æ—¶é•¿: {info.avg_duration:.2f}ç§’")
                print()
    
    def test_stt(self):
        """æµ‹è¯• STT æ¨¡å—"""
        print_title("STT è¯­éŸ³è½¬æ–‡æœ¬æµ‹è¯•")
        
        if not self.modules_initialized['stt']:
            print_error("STT æ¨¡å—æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œç³»ç»Ÿåˆå§‹åŒ–")
            return
        
        print_info("ä½¿ç”¨åˆæˆéŸ³é¢‘è¿›è¡Œ STT æµ‹è¯•")
        print_warning("æ³¨æ„: åˆæˆéŸ³é¢‘è¯†åˆ«å¯èƒ½å¤±è´¥ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰")
        print()
        
        try:
            # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
            audio = generate_test_audio(duration=2.0, seed=42)
            
            print_info("å¼€å§‹è¯†åˆ«...")
            
            with PerformanceTimer() as timer:
                result = self.stt_recognizer.recognize(audio)
            
            print()
            print_subtitle("è¯†åˆ«ç»“æœ")
            print(f"æˆåŠŸ: {result.success}")
            print(f"æ–‡æœ¬: {result.text}")
            print(f"ç½®ä¿¡åº¦: {result.confidence:.3f}")
            print(f"è¯­è¨€: {result.language}")
            print(f"å¼•æ“: {result.engine_type}")
            print(f"å¤„ç†æ—¶é—´: {result.processing_time:.1f} ms")
            print(f"æ€»è€—æ—¶: {timer.elapsed_ms:.1f} ms")
            
            if result.error_message:
                print(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
        
        except Exception as e:
            logger.error(f"STT æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
            print_error(f"STT æµ‹è¯•å¤±è´¥: {e}")
    
    def test_memory(self):
        """æµ‹è¯•è®°å¿†ç®¡ç†æ¨¡å—"""
        print_title("è®°å¿†ç®¡ç†æµ‹è¯•")
        
        if not self.modules_initialized['memory']:
            print_error("è®°å¿†ç®¡ç†æ¨¡å—æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œç³»ç»Ÿåˆå§‹åŒ–")
            return
        
        options = {
            '1': 'åˆ›å»ºå¥½å‹æ¡£æ¡ˆ',
            '2': 'æ·»åŠ å¯¹è¯è®°å½•',
            '3': 'æ£€ç´¢è®°å¿†',
            '4': 'æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯'
        }
        
        choice = show_menu("è®°å¿†ç®¡ç†æµ‹è¯•", options)
        
        if choice == '1':
            self.test_memory_create_profile()
        elif choice == '2':
            self.test_memory_add_conversation()
        elif choice == '3':
            self.test_memory_retrieve()
        elif choice == '4':
            self.test_memory_stats()
    
    def test_memory_create_profile(self):
        """æµ‹è¯•åˆ›å»ºå¥½å‹æ¡£æ¡ˆ"""
        print_subtitle("åˆ›å»ºå¥½å‹æ¡£æ¡ˆ")
        
        name = get_user_input("å¥½å‹å§“å")
        if not name:
            print_warning("å·²å–æ¶ˆ")
            return
        
        preferences = get_user_input("åå¥½è¯é¢˜ï¼ˆé€—å·åˆ†éš”ï¼‰", "æ¸¸æˆ,åŠ¨æ¼«")
        avoid_topics = get_user_input("é¿å…è¯é¢˜ï¼ˆé€—å·åˆ†éš”ï¼‰", "æ”¿æ²»")
        personality = get_user_input("æ€§æ ¼ç‰¹ç‚¹", "æ´»æ³¼")
        
        try:
            friend_id = self.memory_manager.create_friend_profile(
                name=name,
                voice_profile_path=f"data/speaker_profiles/{name}.npy",
                preferences=preferences.split(',') if preferences else [],
                avoid_topics=avoid_topics.split(',') if avoid_topics else [],
                personality=personality
            )
            
            print_success(f"\nå¥½å‹æ¡£æ¡ˆåˆ›å»ºæˆåŠŸï¼")
            print(f"å¥½å‹ID: {friend_id}")
            print(f"å§“å: {name}")
            print(f"åå¥½: {preferences}")
        
        except Exception as e:
            logger.error(f"åˆ›å»ºæ¡£æ¡ˆå¤±è´¥: {e}", exc_info=True)
            print_error(f"åˆ›å»ºå¤±è´¥: {e}")
    
    def test_memory_add_conversation(self):
        """æµ‹è¯•æ·»åŠ å¯¹è¯è®°å½•"""
        print_subtitle("æ·»åŠ å¯¹è¯è®°å½•")
        
        # è·å–ç°æœ‰å¥½å‹
        try:
            stats = self.memory_manager.get_statistics()
            if stats.get('total_friends', 0) == 0:
                print_warning("å°šæœªåˆ›å»ºå¥½å‹æ¡£æ¡ˆï¼Œè¯·å…ˆåˆ›å»ºå¥½å‹")
                return
            
            friend_id = get_user_input("å¥½å‹IDï¼ˆæˆ–è¾“å…¥æ–°IDï¼‰")
            if not friend_id:
                print_warning("å·²å–æ¶ˆ")
                return
            
            text = get_user_input("å¯¹è¯å†…å®¹")
            if not text:
                print_warning("å·²å–æ¶ˆ")
                return
            
            conv_id = self.memory_manager.add_conversation(
                friend_id=friend_id,
                transcript=text,
                speaker_id=friend_id,
                event_type="STATEMENT"
            )
            
            print_success(f"\nå¯¹è¯è®°å½•å·²æ·»åŠ ï¼")
            print(f"å¯¹è¯ID: {conv_id}")
        
        except Exception as e:
            logger.error(f"æ·»åŠ å¯¹è¯å¤±è´¥: {e}", exc_info=True)
            print_error(f"æ·»åŠ å¤±è´¥: {e}")
    
    def test_memory_retrieve(self):
        """æµ‹è¯•è®°å¿†æ£€ç´¢"""
        print_subtitle("è®°å¿†æ£€ç´¢")
        
        query = get_user_input("æ£€ç´¢æŸ¥è¯¢")
        if not query:
            print_warning("å·²å–æ¶ˆ")
            return
        
        try:
            memories = self.memory_manager.retrieve_memories(
                query=query,
                top_k=5
            )
            
            print(f"\næ‰¾åˆ° {len(memories)} æ¡ç›¸å…³è®°å¿†:\n")
            
            for i, memory in enumerate(memories, 1):
                print(f"{i}. {memory.content[:50]}...")
                print(f"   ç›¸ä¼¼åº¦: {memory.similarity_score:.3f}")
                print(f"   æ—¶é—´è¡°å‡: {memory.time_decay_factor:.3f}")
                print(f"   æ—¶é—´: {format_timestamp(memory.timestamp)}")
                print()
        
        except Exception as e:
            logger.error(f"æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
            print_error(f"æ£€ç´¢å¤±è´¥: {e}")
    
    def test_memory_stats(self):
        """æŸ¥çœ‹è®°å¿†ç®¡ç†ç»Ÿè®¡"""
        print_subtitle("è®°å¿†ç®¡ç†ç»Ÿè®¡")
        
        try:
            stats = self.memory_manager.get_statistics()
            
            print(f"å¥½å‹æ•°é‡: {stats.get('total_friends', 0)}")
            print(f"å¯¹è¯æ€»æ•°: {stats.get('total_conversations', 0)}")
            print(f"å‘é‡æ€»æ•°: {stats.get('total_vectors', 0)}")
            print(f"å‘é‡ç»´åº¦: {stats.get('embedding_dimension', 0)}")
        
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
            print_error(f"è·å–ç»Ÿè®¡å¤±è´¥: {e}")
    
    def run_full_pipeline_test(self):
        """è¿è¡Œå®Œæ•´æµç¨‹æµ‹è¯• - é€‰æ‹©æµ‹è¯•æ¨¡å¼"""
        print_title("å®Œæ•´æµç¨‹æµ‹è¯•")
        
        print_warning("æ­¤åŠŸèƒ½éœ€è¦æ‰€æœ‰æ¨¡å—éƒ½å·²åˆå§‹åŒ–")
        print_info("å°†æµ‹è¯•: éŸ³é¢‘é‡‡é›† -> VAD -> è¯´è¯äººè¯†åˆ« -> STT -> è®°å¿†å­˜å‚¨")
        print()
        
        # æ£€æŸ¥æ¨¡å—çŠ¶æ€
        all_ready = all(self.modules_initialized.values())
        
        if not all_ready:
            print_error("éƒ¨åˆ†æ¨¡å—æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿è¡Œå®Œæ•´æµç¨‹")
            print_info("è¯·å…ˆè¿è¡Œ 'ç³»ç»Ÿåˆå§‹åŒ–' åŠŸèƒ½")
            return
        
        # é€‰æ‹©æµ‹è¯•æ¨¡å¼
        options = {
            '1': 'å®æ—¶é‡‡é›†æµ‹è¯• - ä»éŸ³é¢‘è®¾å¤‡é‡‡é›†å¹¶å¤„ç†ï¼ˆæ¸¸æˆå†…æµ‹è¯•ï¼‰',
            '2': 'æ¨¡æ‹ŸéŸ³é¢‘æµ‹è¯• - ä½¿ç”¨åˆæˆéŸ³é¢‘æµ‹è¯•ï¼ˆå¿«é€ŸéªŒè¯ï¼‰'
        }
        
        choice = show_menu("é€‰æ‹©æµ‹è¯•æ¨¡å¼", options)
        
        if choice == '0':
            return
        elif choice == '1':
            self.run_full_pipeline_test_realtime()
        elif choice == '2':
            self.run_full_pipeline_test_simulated()
    
    def run_full_pipeline_test_simulated(self):
        """è¿è¡Œæ¨¡æ‹ŸéŸ³é¢‘çš„å®Œæ•´æµç¨‹æµ‹è¯•"""
        print_title("æ¨¡æ‹ŸéŸ³é¢‘å®Œæ•´æµç¨‹æµ‹è¯•")
        
        if not confirm("æ˜¯å¦å¼€å§‹æ¨¡æ‹Ÿæµ‹è¯•ï¼Ÿ"):
            return
        
        print()
        print_subtitle("æ­¥éª¤ 1: ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")
        test_audio = generate_speech_audio(duration=2.0)
        print_success("æµ‹è¯•éŸ³é¢‘ç”Ÿæˆå®Œæˆ")
        
        print()
        print_subtitle("æ­¥éª¤ 2: VAD æ£€æµ‹")
        # TODO: å®ç°å®Œæ•´æµç¨‹
        print_info("VAD æ£€æµ‹... (æ¼”ç¤º)")
        
        print()
        print_subtitle("æ­¥éª¤ 3: è¯´è¯äººè¯†åˆ«")
        print_info("è¯´è¯äººè¯†åˆ«... (æ¼”ç¤º)")
        
        print()
        print_subtitle("æ­¥éª¤ 4: è¯­éŸ³è½¬æ–‡æœ¬")
        print_info("STT è¯†åˆ«... (æ¼”ç¤º)")
        
        print()
        print_subtitle("æ­¥éª¤ 5: è®°å¿†å­˜å‚¨ä¸æ£€ç´¢")
        print_info("å­˜å‚¨å¯¹è¯... (æ¼”ç¤º)")
        
        print()
        print_success("æ¨¡æ‹Ÿæµ‹è¯•å®Œæˆï¼")
    
    def run_full_pipeline_test_realtime(self):
        """è¿è¡Œå®æ—¶å®Œæ•´æµç¨‹æµ‹è¯•ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰"""
        import threading
        import queue
        import json
        from datetime import datetime
        
        print_title("å®æ—¶å®Œæ•´æµç¨‹æµ‹è¯•")
        print_info("è¿™å°†ä»éŸ³é¢‘è®¾å¤‡å®æ—¶é‡‡é›†å¹¶å¤„ç†è¯­éŸ³")
        print()
        
        # é…ç½®å‚æ•°
        print_subtitle("æµ‹è¯•é…ç½®")
        duration = get_number_input("æµ‹è¯•æ—¶é•¿ï¼ˆç§’ï¼Œ0è¡¨ç¤ºæ‰‹åŠ¨åœæ­¢ï¼‰", 0)
        save_transcripts = confirm("æ˜¯å¦ä¿å­˜è¯†åˆ«ç»“æœï¼Ÿ", default=True)
        
        # æ£€æŸ¥å·²æ³¨å†Œå¥½å‹
        registered = self.speaker_recognizer.get_registered_speakers()
        if not registered:
            print_warning("å°šæœªæ³¨å†Œä»»ä½•å¥½å‹ï¼Œå°†è·³è¿‡è¯´è¯äººè¯†åˆ«")
            enable_speaker = False
        else:
            print_info(f"å·²æ³¨å†Œ {len(registered)} ä½å¥½å‹")
            for speaker_id in registered:
                info = self.speaker_recognizer.get_speaker_info(speaker_id)
                if info:
                    print(f"  - {info.name}")
            enable_speaker = True
        
        print()
        if not confirm("ç¡®è®¤é…ç½®ï¼Œå¼€å§‹æµ‹è¯•ï¼Ÿ"):
            return
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
        stats = {
            'start_time': time.time(),
            'audio_frames': 0,
            'vad_segments': 0,
            'speaker_matches': 0,
            'speaker_unknowns': 0,
            'stt_success': 0,
            'stt_failed': 0,
            'memory_saved': 0,
            'total_audio_duration': 0,
            'results': []
        }
        
        # åˆ›å»ºé˜Ÿåˆ—å’Œæ§åˆ¶æ ‡å¿—
        audio_queue = queue.Queue(maxsize=100)
        vad_queue = queue.Queue(maxsize=20)
        running = {'flag': True}
        paused = {'flag': False}
        
        # VADå›è°ƒï¼šæ£€æµ‹åˆ°è¯­éŸ³ç‰‡æ®µ
        def vad_callback(segment, metadata):
            if running['flag'] and not paused['flag']:
                stats['vad_segments'] += 1
                vad_queue.put((segment, metadata))
        
        # è®¾ç½®VADå›è°ƒ
        self.vad_detector.set_callback(vad_callback)
        
        # éŸ³é¢‘é‡‡é›†å›è°ƒ
        def audio_callback(audio_data, timestamp):
            if running['flag']:
                stats['audio_frames'] += 1
                stats['total_audio_duration'] = len(audio_data) / 16000
                # å°†éŸ³é¢‘æ•°æ®ä¼ é€’ç»™VAD
                try:
                    self.vad_detector.process_audio(audio_data, timestamp)
                except Exception as e:
                    logger.error(f"VADå¤„ç†é”™è¯¯: {e}")
        
        # è·å–éŸ³é¢‘è®¾å¤‡
        from audio_capture import DeviceManager, AudioCapturer
        device_manager = DeviceManager()
        loopback = device_manager.get_default_wasapi_loopback()
        
        if not loopback:
            print_error("æœªæ‰¾åˆ° WASAPI Loopback è®¾å¤‡")
            return
        
        print_info(f"ä½¿ç”¨è®¾å¤‡: {loopback['name']}")
        print()
        
        # åˆ›å»ºéŸ³é¢‘é‡‡é›†å™¨
        try:
            capturer = AudioCapturer(
                loopback_device=loopback['index'],
                samplerate=16000,
                channels=1,
                chunk_size=480
            )
            capturer.set_loopback_callback(audio_callback)
        except Exception as e:
            print_error(f"éŸ³é¢‘é‡‡é›†å™¨åˆ›å»ºå¤±è´¥: {e}")
            return
        
        # å¤„ç†çº¿ç¨‹
        def processing_thread():
            """å¤„ç†VADæ£€æµ‹åˆ°çš„è¯­éŸ³ç‰‡æ®µ"""
            while running['flag']:
                try:
                    # ä»é˜Ÿåˆ—è·å–è¯­éŸ³ç‰‡æ®µï¼ˆè¶…æ—¶1ç§’ï¼‰
                    segment, metadata = vad_queue.get(timeout=1.0)
                    
                    if paused['flag']:
                        continue
                    
                    # è¯´è¯äººè¯†åˆ«
                    speaker_result = None
                    speaker_name = "æœªçŸ¥"
                    
                    if enable_speaker:
                        try:
                            speaker_result = self.speaker_recognizer.recognize(
                                audio_segment=segment,
                                timestamp=time.time(),
                                sample_rate=16000
                            )
                            
                            if speaker_result.matched:
                                stats['speaker_matches'] += 1
                                info = self.speaker_recognizer.get_speaker_info(speaker_result.speaker_id)
                                speaker_name = info.name if info else speaker_result.speaker_id
                            else:
                                stats['speaker_unknowns'] += 1
                                speaker_name = "æœªçŸ¥è¯´è¯äºº"
                        except Exception as e:
                            logger.error(f"è¯´è¯äººè¯†åˆ«é”™è¯¯: {e}")
                            stats['speaker_unknowns'] += 1
                    
                    # STTè¯†åˆ«ï¼ˆä»…å¯¹å·²åŒ¹é…çš„è¯´è¯äººï¼‰
                    if not enable_speaker or (speaker_result and speaker_result.matched):
                        try:
                            stt_result = self.stt_recognizer.recognize(segment)
                            
                            if stt_result.success and stt_result.text.strip():
                                stats['stt_success'] += 1
                                
                                # ä¿å­˜åˆ°è®°å¿†
                                try:
                                    if enable_speaker and speaker_result:
                                        conv_id = self.memory_manager.add_conversation(
                                            friend_id=speaker_result.speaker_id,
                                            transcript=stt_result.text,
                                            speaker_id=speaker_result.speaker_id,
                                            event_type="STATEMENT"
                                        )
                                        stats['memory_saved'] += 1
                                except Exception as e:
                                    logger.error(f"è®°å¿†ä¿å­˜é”™è¯¯: {e}")
                                
                                # è®°å½•ç»“æœ
                                result = {
                                    'timestamp': time.time(),
                                    'speaker': speaker_name,
                                    'confidence': speaker_result.confidence if speaker_result else 0,
                                    'text': stt_result.text,
                                    'stt_confidence': stt_result.confidence,
                                    'duration': metadata.get('duration', 0)
                                }
                                stats['results'].append(result)
                                
                                # å®æ—¶æ˜¾ç¤º
                                elapsed = time.time() - stats['start_time']
                                conf = speaker_result.confidence if speaker_result else 0
                                print(f"\n[{format_duration(elapsed)}] {speaker_name} ({conf:.2f}):")
                                print(f"  \"{stt_result.text}\"")
                                print(f"  STTç½®ä¿¡åº¦: {stt_result.confidence:.2f} | æ—¶é•¿: {metadata.get('duration', 0):.2f}s")
                            else:
                                stats['stt_failed'] += 1
                        except Exception as e:
                            logger.error(f"STTè¯†åˆ«é”™è¯¯: {e}")
                            stats['stt_failed'] += 1
                
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†çº¿ç¨‹é”™è¯¯: {e}", exc_info=True)
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        proc_thread = threading.Thread(target=processing_thread, daemon=True)
        proc_thread.start()
        
        # å¯åŠ¨éŸ³é¢‘é‡‡é›†
        print_subtitle("å¼€å§‹å®æ—¶æµ‹è¯•")
        print_info("æŒ‰ Ctrl+C åœæ­¢æµ‹è¯•")
        print_separator()
        print()
        
        try:
            capturer.start()
            start_time = time.time()
            
            # ä¸»å¾ªç¯
            while running['flag']:
                time.sleep(0.5)
                
                # æ£€æŸ¥æ—¶é•¿
                if duration > 0 and (time.time() - start_time) >= duration:
                    print_info("\næµ‹è¯•æ—¶é•¿å·²åˆ°ï¼Œåœæ­¢æµ‹è¯•")
                    break
                
                # æ˜¾ç¤ºç®€å•çŠ¶æ€ï¼ˆæ¯5ç§’ï¼‰
                if int(time.time() - start_time) % 5 == 0:
                    elapsed = time.time() - start_time
                    print(f"\rè¿è¡Œä¸­... {format_duration(elapsed)} | "
                          f"VADç‰‡æ®µ: {stats['vad_segments']} | "
                          f"è¯†åˆ«æˆåŠŸ: {stats['stt_success']}", end='', flush=True)
        
        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        finally:
            # åœæ­¢é‡‡é›†å’Œå¤„ç†
            running['flag'] = False
            capturer.stop()
            proc_thread.join(timeout=3)
        
        # æ˜¾ç¤ºç»Ÿè®¡æŠ¥å‘Š
        print("\n")
        print_separator("=")
        print_title("æµ‹è¯•å®Œæˆ - ç»Ÿè®¡æŠ¥å‘Š")
        print_separator("=")
        
        total_time = time.time() - stats['start_time']
        
        print(f"\næµ‹è¯•æ—¶é•¿: {format_duration(total_time)}")
        print(f"éŸ³é¢‘å¸§æ•°: {stats['audio_frames']}")
        print(f"VADæ£€æµ‹ç‰‡æ®µ: {stats['vad_segments']}")
        
        if enable_speaker:
            print(f"\nè¯´è¯äººè¯†åˆ«:")
            print(f"  åŒ¹é…æˆåŠŸ: {stats['speaker_matches']}")
            print(f"  æœªçŸ¥è¯´è¯äºº: {stats['speaker_unknowns']}")
            if stats['speaker_matches'] + stats['speaker_unknowns'] > 0:
                match_rate = stats['speaker_matches'] / (stats['speaker_matches'] + stats['speaker_unknowns']) * 100
                print(f"  åŒ¹é…ç‡: {match_rate:.1f}%")
        
        print(f"\nSTTè¯†åˆ«:")
        print(f"  æˆåŠŸ: {stats['stt_success']}")
        print(f"  å¤±è´¥: {stats['stt_failed']}")
        if stats['stt_success'] + stats['stt_failed'] > 0:
            success_rate = stats['stt_success'] / (stats['stt_success'] + stats['stt_failed']) * 100
            print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
        
        print(f"\nè®°å¿†ç®¡ç†:")
        print(f"  ä¿å­˜å¯¹è¯: {stats['memory_saved']} æ¡")
        
        # ä¿å­˜ç»“æœ
        if save_transcripts and stats['results']:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            transcript_file = project_root / f"tests/integrated_test_{timestamp}_transcripts.txt"
            report_file = project_root / f"tests/integrated_test_{timestamp}_report.json"
            
            # ä¿å­˜æ–‡æœ¬è½¬å½•
            try:
                with open(transcript_file, 'w', encoding='utf-8') as f:
                    f.write(f"VRChat ç¤¾äº¤è¾…åŠ©å·¥å…· - å®Œæ•´æµç¨‹æµ‹è¯•ç»“æœ\n")
                    f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"æµ‹è¯•æ—¶é•¿: {format_duration(total_time)}\n")
                    f.write("=" * 60 + "\n\n")
                    
                    for i, result in enumerate(stats['results'], 1):
                        elapsed = result['timestamp'] - stats['start_time']
                        f.write(f"[{format_duration(elapsed)}] {result['speaker']} ({result['confidence']:.2f}):\n")
                        f.write(f"  \"{result['text']}\"\n")
                        f.write(f"  STTç½®ä¿¡åº¦: {result['stt_confidence']:.2f} | æ—¶é•¿: {result['duration']:.2f}s\n\n")
                
                print(f"\nè½¬å½•ç»“æœå·²ä¿å­˜: {transcript_file.name}")
            except Exception as e:
                logger.error(f"ä¿å­˜è½¬å½•å¤±è´¥: {e}")
            
            # ä¿å­˜JSONæŠ¥å‘Š
            try:
                report = {
                    'test_metadata': {
                        'timestamp': datetime.now().isoformat(),
                        'duration_seconds': total_time,
                        'test_mode': 'realtime'
                    },
                    'module_statistics': {
                        'audio_frames': stats['audio_frames'],
                        'vad_segments': stats['vad_segments'],
                        'speaker_matches': stats['speaker_matches'],
                        'speaker_unknowns': stats['speaker_unknowns'],
                        'stt_success': stats['stt_success'],
                        'stt_failed': stats['stt_failed'],
                        'memory_saved': stats['memory_saved']
                    },
                    'results': stats['results']
                }
                
                with open(report_file, 'w', encoding='utf-8') as f:
                    json.dump(report, f, ensure_ascii=False, indent=2)
                
                print(f"æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file.name}")
            except Exception as e:
                logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
        
        print()
        print_success("âœ“ å®æ—¶å®Œæ•´æµç¨‹æµ‹è¯•å®Œæˆï¼")
    
    def show_data_management_menu(self):
        """æ˜¾ç¤ºæ•°æ®ç®¡ç†èœå•"""
        while True:
            options = {
                '1': 'å¥½å‹ç®¡ç†',
                '2': 'å¯¹è¯è®°å½•æŸ¥çœ‹',
                '3': 'æ•°æ®ç»Ÿè®¡',
                '4': 'æ•°æ®æ¸…ç†'
            }
            
            choice = show_menu("æ•°æ®ç®¡ç†", options)
            
            if choice == '0':
                break
            elif choice == '1':
                self.manage_friends()
            elif choice == '2':
                self.view_conversations()
            elif choice == '3':
                self.show_data_stats()
            elif choice == '4':
                self.cleanup_data()
            
            if choice != '0':
                wait_for_enter()
    
    def manage_friends(self):
        """å¥½å‹ç®¡ç†"""
        print_title("å¥½å‹ç®¡ç†")
        print_info("æ­¤åŠŸèƒ½æ•´åˆäº†è¯´è¯äººè¯†åˆ«å’Œè®°å¿†ç®¡ç†çš„å¥½å‹æ•°æ®")
    
    def view_conversations(self):
        """æŸ¥çœ‹å¯¹è¯è®°å½•"""
        print_title("å¯¹è¯è®°å½•")
        print_info("æ˜¾ç¤ºå†å²å¯¹è¯è®°å½•")
    
    def show_data_stats(self):
        """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
        print_title("æ•°æ®ç»Ÿè®¡")
        
        # æ˜¾ç¤ºå„æ¨¡å—çš„ç»Ÿè®¡ä¿¡æ¯
        if self.modules_initialized['speaker']:
            print_subtitle("è¯´è¯äººè¯†åˆ«", "-")
            registered = self.speaker_recognizer.get_registered_speakers()
            print(f"å·²æ³¨å†Œå¥½å‹: {len(registered)} ä½")
            print()
        
        if self.modules_initialized['memory']:
            print_subtitle("è®°å¿†ç®¡ç†", "-")
            try:
                stats = self.memory_manager.get_statistics()
                print(f"å¥½å‹æ¡£æ¡ˆ: {stats.get('total_friends', 0)} ä¸ª")
                print(f"å¯¹è¯è®°å½•: {stats.get('total_conversations', 0)} æ¡")
                print(f"å‘é‡æ•°æ®: {stats.get('total_vectors', 0)} æ¡")
            except:
                print_warning("æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯")
    
    def cleanup_data(self):
        """æ•°æ®æ¸…ç†"""
        print_title("æ•°æ®æ¸…ç†")
        print_warning("æ­¤æ“ä½œå°†åˆ é™¤æ•°æ®ï¼Œè¯·è°¨æ…æ“ä½œï¼")
        
        if not confirm("ç¡®å®šè¦æ¸…ç†æ•°æ®å—ï¼Ÿ", default=False):
            print_info("å·²å–æ¶ˆ")
            return
        
        print_info("æ•°æ®æ¸…ç†åŠŸèƒ½å°šæœªå®ç°")
    
    def show_system_info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        print_title("ç³»ç»Ÿä¿¡æ¯")
        
        print_subtitle("æ¨¡å—çŠ¶æ€", "-")
        for module, status in self.modules_initialized.items():
            status_text = "âœ“ å·²åˆå§‹åŒ–" if status else "âœ— æœªåˆå§‹åŒ–"
            if status:
                print_success(f"{module.upper()}: {status_text}")
            else:
                print_error(f"{module.upper()}: {status_text}")
        
        print()
        print_subtitle("ç¯å¢ƒä¿¡æ¯", "-")
        print(f"Python ç‰ˆæœ¬: {sys.version.split()[0]}")
        print(f"é¡¹ç›®è·¯å¾„: {project_root}")
        print(f"é…ç½®ç›®å½•: {self.config_dir}")
        print(f"æ•°æ®ç›®å½•: {self.data_dir}")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("æ¸…ç†èµ„æº...")
        
        if self.audio_capturer:
            try:
                self.audio_capturer.stop()
            except:
                pass
        
        logger.info("èµ„æºæ¸…ç†å®Œæˆ")


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='VRChat ç¤¾äº¤è¾…åŠ©å·¥å…· - åŠŸèƒ½é›†æˆæµ‹è¯•ç¨‹åº',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--init', action='store_true',
                       help='ä»…è¿è¡Œåˆå§‹åŒ–æ£€æŸ¥')
    parser.add_argument('--module', type=str,
                       help='ç›´æ¥è¿›å…¥æŒ‡å®šæ¨¡å—æµ‹è¯• (audio/vad/speaker/stt/memory)')
    parser.add_argument('--full', action='store_true',
                       help='ç›´æ¥è¿è¡Œå®Œæ•´æµç¨‹æµ‹è¯•')
    parser.add_argument('--debug', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡é¿å… PyTorch æ­»é”é—®é¢˜ï¼ˆWindowsï¼‰
    import os
    os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
    os.environ['OMP_NUM_THREADS'] = '1'
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test = IntegratedTest()
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œ
    if args.init:
        test.initialize_system()
    elif args.module:
        test.initialize_system()
        # TODO: æ ¹æ®å‚æ•°ç›´æ¥è¿›å…¥å¯¹åº”æ¨¡å—æµ‹è¯•
        print_info(f"è¿›å…¥ {args.module} æ¨¡å—æµ‹è¯•...")
    elif args.full:
        test.initialize_system()
        test.run_full_pipeline_test()
    else:
        # æ­£å¸¸å¯åŠ¨
        test.run()


if __name__ == '__main__':
    # Windows å¤šè¿›ç¨‹ä¿æŠ¤
    import multiprocessing
    multiprocessing.freeze_support()
    
    try:
        main()
    except KeyboardInterrupt:
        print()
        print_warning("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}", exc_info=True)
        print_error(f"ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1)
